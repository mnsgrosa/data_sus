services:
  ollama:
    build: ./ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - data_sus_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  api:
    build: .
    container_name: data_sus_api
    command: python -m src.api.fast
    ports:
      - "8000:8000"
    volumes:
      - ./:/app
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_HOST=http://host.docker.internal:11434 
    networks:
      - data_sus_network
    extra_hosts:
      - "host.docker.internal:host-gateway"

  agent:
    build: .
    container_name: data_sus_agent
    command: streamlit run app.py
    ports:
      - "8501:8501"
    volumes:
      - ./:/app
    environment:
      - PYTHONUNBUFFERED=1
    depends_on:
      - api
    networks:
      - data_sus_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

networks:
  data_sus_network:
    driver: bridge

volumes:
  ollama_data: